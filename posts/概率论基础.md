---
date: 2024-12-02
title: 实用（？）中等概率论
tags:
  - math
  - 概率
description: 好像不是很初等的概率论，想到啥写啥了，属于我目前对概率论的理解。好像也不咋实用（），主要是借高等的概念消除掉一些特殊情况的讨论（离散or连续，密度函数不存在，不可积，……）。
---

# {{ $frontmatter.title }}

## 前言

写蒙特卡洛积分的文章的时候上头了，写了一堆概率论基础相关的东西。寻思着干脆单独开一篇文章，以后要是需要用到相关知识，可以直接引用这篇文章。文章中有大量的外部引用，也是为了方便读者~~和我~~查阅相关概念。

严谨地构建整套概率理论需要实变和测度理论的大量前置支撑，我也不想事无巨细地讨论全部细节，搞的和教科书一样。本文主要还是讨论一些intuitive的理解和可能能用到的一些概念，因此会跳过不少细节。完备的定义和证明可以参考文中的外链和相关教科书。

## 概率空间

一个**概率空间**由三元组$(\Omega, \mathscr{F}, \mathbb{P})$组成。对于没有实变基础的读者，可以做如下理解：

- $\Omega$（**样本空间**） 就是所有可能的结果，比如掷骰子，$\Omega = \{1, 2, 3, 4, 5, 6\}$。
- $\mathscr{F}$（**事件空间**）是可能结果的组合构成的集合。同样是掷骰子的例子，$\{1, 2\}$，$\{2, 4, 5\}$等都是$\mathscr{F}$的元素。
- $\mathbb{P}$（**概率测度**）是定义在$\mathscr{F}$上的一种“面积/长度”（**测度**），除了满足通常面积所需的性质之外，我们还要求$\mathbb{P}(\Omega) = 1$，即所有可能结果的测度之和为1。

:::info 技术细节（测度论相关）

> 测度理论就是试图给任意点集定义长度或者面积而发展出来的。

- 由于不是任意集合都能合理地定义面积（例如[Vatali集](https://en.wikipedia.org/wiki/Vitali_set)），对于一般的不可数集$\Omega$，我们不能直接取$\mathscr{F}=2^{\Omega}$，而是需要剔除掉那些无法定义面积的集合。
- 为了定义面积，我们选取的集合需要满足一些性质，满足这些性质的集合族被称为[σ-代数](https://en.wikipedia.org/wiki/%CE%A3-algebra)。因此，$\mathscr{F}$应当是$\Omega$上的一个$\sigma$**-代数**。
- 能定义良好的面积的集合（$\sigma$-代数的元素）称为**可测集**，反之称为**不可测集**。
- **可测函数**是能保证可测集的原像也是可测集的函数。直观上，这样的函数能让我们用值域的“长度”乘上定义域的“长度”来定义积分。

:::

在概率空间这套语言下，我们可以定义**随机变量**$X$，它是一个从$\Omega$到$\mathbb{R}$的可测函数。$X$的**分布函数**$F_X(x)$定义为：

$$
F_X(x) = \mathbb{P}(X \leq x) = \mathbb{P}(\{\omega \in \Omega \mid X(\omega) \leq x\})
$$

按照定义以及$\sigma$-代数的性质，可以证明$F_X(x)$**单增右连续**，并且$F(-\infty)=0$，$F(\infty)=1$。

另外，如果存在函数$f_X$，满足：

$$
\int_{-\infty}^x f_X(t) \mathrm{d}t = F_X(x)
$$

那么称$f_X$为$X$的**概率密度函数**。显然如果$F_X$可导，那么它的导数是一个概率密度函数。

因为在一个零测集上改变$f_X$值并不会影响积分结果，所以$f_X$如果存在，则不是唯一的。

:::info Further Reading

- [Fiddie的概率论复习笔记(3)——概率的公理化定义](https://zhuanlan.zhihu.com/p/61729415)
- [Fiddie的概率论复习笔记(4)——概率的公理化定义延伸](https://zhuanlan.zhihu.com/p/62172705)

:::

## Stieltjes积分与期望

为了统一离散型和连续型随机变量的期望定义，我们引入所谓的**Stieltjes积分**。回想Riemann积分的定义：

$$
\int_a^b f(x) \mathrm{d}x = \lim_{\|P^*\| \to 0} \sum_{i=1}^n f(x_i^*) \Delta x_i
$$

在上面的定义中，如果我们不对$x$做积分，而是改为对某个实值函数$g(x)$做积分，那么就得到了[Riemann-Stieltjes积分](https://en.wikipedia.org/wiki/Riemann%E2%80%93Stieltjes_integral)：

$$
\int_a^b f \mathrm{d}g = \lim_{\|P^*\| \to 0} \sum_{i=1}^n f(x_i^*) \Delta g_i
$$

> S积分实质上是更换了区间长度的度量方式，应当将$\Delta g$视为一种测度。

把[Abel求和公式的差分形式](https://www.zhihu.com/question/376152601/answer/1438773675)$\Delta (f_i g_i) = f_{i+1} \Delta g_i + g_i \Delta f_i$代入到R-S积分的定义中，我们可以得到**分部积分**公式：

$$
\int_a^b f \mathrm{d}g = (fg)\Big\vert_a^b - \int_a^b g \mathrm{d}f
$$

类似地，我们也有**换元积分**公式：

$$
\int_A^B (f\circ\varphi) \mathrm{d}(\alpha\circ\varphi) = \int_a^b f \mathrm{d}\alpha
$$

其中，$\varphi: [A, B] \to [a, b]$是连续的有界变差函数，且$\varphi(A)=a$，$\varphi(B)=b$。

### R-S可积性

若$f$关于$g$的R-S积分存在，则称$f$关于$g$ **R-S可积**，记为$f\in \mathcal{R}(g)$

关于R-S可积性，我们有以下结论：

:::tip R-S积分的可积性

- 若$f$在$[a, b]$上有界且**几乎处处连续**，$g$在$[a, b]$上单调**右连续**且在$f$的间断点上连续，那么$f\in \mathcal{R}(g)$
- 若$f$在$[a, b]$上连续，$g$在$[a, b]$上单调，那么$f\in \mathcal{R}(g)$
  :::

由分部积分公式可知，上述R-S可积的结论中关于$f$和$g$的要求可以互换。

结论2的证明可以在Rudin的数学分析原理中找到（定理6.8）。

结论1的证明则需要仿照L积分和R积分的关系引入L-S积分的概念。需要注意的是，为了定义L-S积分，我们必须要求$g$右连续，否则关于$g$的L-S测度可能不存在。（参考分布函数右连续和$\sigma$-代数的关系）

**注**：考虑到[有界变差函数](https://en.wikipedia.org/wiki/Bounded_variation)总是可以分解成两个单调函数的差，所以上面关于单调的要求不难推广到有界变差的情况。

### R-S积分与Riemann积分和离散求和的联系

显然当$g(x)=x$时，R-S积分退化为Riemann积分。更一般地，如果存在密度函数$\rho(x)$使得$g(x)=\int_a^x \rho(t) \mathrm{d}t$，那么以下等式成立：

$$
\int_a^b f \mathrm{d}g = \int_a^b f(x) \rho(x) \mathrm{d}x
$$


如果$g$可导，那么由中值定理和R-S积分的定义，我们不难得到：

$$
\int_a^b f \mathrm{d}g = \int_a^b f g' \mathrm{d}x
$$

因此，如果$\varphi$可微，前述的换元积分公式也可以写作我们熟悉的形式：

$$
\int_a^b f \mathrm{d}x = \int_A^B f(\varphi(y)) \varphi'(y) \mathrm{d}y
$$

:::info 技术细节（导函数的可积性）
* 可导函数的导函数不一定Riemann可积，即使保证导数有界也仍然有反例（[Volterra函数](https://tigertooth4.github.io/post/2022-05/volterra-function/)）。
* 即便将可积的定义放宽到Lebesgue可积，也仍然有导函数不可积的例子（可以参考[这个StackExchange讨论](https://math.stackexchange.com/questions/2382119/are-all-derivatives-either-lebesgue-integrable-or-improper-riemann-integrable)）。但我们能证明有界的导函数总是Lebesgue可积的。
* 为了使任意导函数可积，我们得使用[Gauge积分（Henstock-Kurzweil积分）](https://en.wikipedia.org/wiki/Henstock%E2%80%93Kurzweil_integral)作为R积分和L积分的推广。
:::

---

引入S积分后，我们可以考察对不连续变量的积分。例如，考虑Heaviside单位阶跃函数$H(x)$：

$$
H(x) = \mathbf{1}_{x\geq 0} = \begin{dcases}
1 & x \geq 0 \\
0 & x < 0 \\
\end{dcases}
$$

如果$s\in (a, b)$，$\alpha(x) =\mathbf{1}_{x\geq s} = H(x-s)$，$f$在$[a, b]$上有界且在$x=s$处连续，那么按定义有：

$$
\int_a^b f \mathrm{d}\alpha = f(s)
$$

进而取$\alpha(x) = \displaystyle \sum_{i=1}^{\infty} c_i \mathbf{1}_{x\geq s_i}$，其中$s_i$互不相同，$\sum c_i$收敛，若$f$在$s_i$处连续，则有

$$
\int_a^b f \mathrm{d}\alpha = \sum_{i=1}^{\infty} c_i f(s_i)
$$

特殊地，我们有

$$
\int_a^b f \mathrm{d}\lfloor x \rfloor = \sum_{n=\lceil a \rceil}^{\lfloor b \rfloor} f(n)


$$

这表明离散求和也可看成是S积分的特殊形式。

至此我们统一了积分和求和的语言，可以统一在S积分的框架下讨论离散和连续的求和问题。

> 本文只讨论了R-S积分，但将Stieltjes测度应用到更一般的Lebesgue积分乃至Gauge积分并不困难。只是一些改善积分性质的技术细节而已，就不过多深入了。

:::info Further Reading

- 数学分析原理（Rudin），第6章 Riemann-Stieltjes积分
- Theories of Integration - The Integrals of Riemann, Lebesgue, Henstock-Kurzweil, and McShane (Douglas S Kurtz, Charles W. Swartz)
- Kurzweil-Stieltjes Integral and Its Applications (Giselle A. Monteiro, Antonín Slavík, Milan Tvrdý)
:::

### 随机变量的期望

使用S积分，我们可以将离散型和连续型随机变量的期望$\mathbb{E}(X)$统一定义为：

$$
\mathbb{E}(X) = \int_{-\infty}^{\infty} x \mathrm{d}F
$$

其中$F$是$X$的分布函数。从这个意义上来说，**随机变量的期望可以理解为在分布函数$F$上的S积分**。

应用分部积分公式，我们也可以把期望表示为：

$$
\mathbb{E}(X) = \int_{0}^{\infty} (1-F) \mathrm{d}x - \int_{-\infty}^{0} F \mathrm{d}x
$$

如果$X$只在$\{0, 1, \cdots\}$上取值，那么则有

$$
\mathbb{E}(X) = \sum_{n=0}^{\infty} (1-F(n)) = \sum_{n=0}^{\infty} \mathbb{P}(X > n)
$$

## Dirac δ-函数与广义密度函数

对一般的分布函数$F(x)$来说，满足

$$
\int_{-\infty}^x f(t) \mathrm{d}t = F(x)
$$

的概率密度函数$f(x)$未必存在：各种离散型随机变量的分布函数就是典型的例子。但很多时候我们又形式上地需要一个密度函数，这时候就不得不引入广义函数相关的理论了。

### Dirac δ-函数

作为最简单的例子，考虑Heaviside阶跃函数$H(x)$的导数。显然通常意义上$H(x)$在$x=0$处不可导，但我们可以形式上地定义一个广义函数$\delta(x)$：

$$
\delta(x)\mathrm{d}x = \mathrm{d} H(x)
$$

按前一节讨论的Stieltjes积分，我们知道$\delta(x)$满足

$$
\int_{-\infty}^{\infty} \delta(x) f(x) \mathrm{d}x =\int_{-\infty}^{\infty} f(x) \mathrm{d}H = f(0)
$$

$\delta(x)$被称为Dirac $\delta$-函数，它并不是通常意义上的函数，而是一个**广义函数**。

### 广义密度函数

关于广义函数的理论涉及到泛函分析的相关知识，这里简单介绍下思路。

我们回归到动机：我们希望给任意分布函数找到对应的密度函数，使得相应的期望计算能够使用密度函数来进行——实际上，**我们并不关心密度函数本身在某一点的值，而只关心它与任意函数乘积的积分**。

我们考虑函数空间上的施瓦兹内积：

$$
\langle f, g \rangle = \int_{\Gamma} f(x) g(x) \mathrm{d}x
$$

在内积这个意义上，$f(x)$这个函数和$\langle f, \cdot \rangle$没有实质的区别，可以认为是（**分布意义上**）等价的。于是我们就用连续线性泛函$\langle f, \cdot \rangle$来代替函数$f(x)$。一般地，任意连续线性泛函未必能对应到某个函数，相当于拓宽了函数的定义，这些“多出来”的函数就是广义函数。

> 利用内积实现广义函数的理论被称为**分布理论**。

:::info 技术细节
* 连续线性泛函$\langle f, \cdot \rangle$是在所谓**测试函数空间**$\mathfrak{D}(\Gamma)$上定义的
* 测试函数$\varphi\in \mathfrak{D}(\Gamma)$满足无穷可微且$\varphi^{(k)}(x)=0$对$x\notin \Gamma$以及$k\in \{0,1,\cdots\}$成立。（即$\varphi^{(k)}(x)$在$\Gamma$上有紧支集。）

:::

#### 弱导数

如果我们将内积中的积分看作Stieltjes积分，那么利用分部积分和测试函数的性质，我们不难得到广义函数的导数：

$$
\begin{aligned}
\langle f', \varphi \rangle &= \int_{\Gamma} f'\varphi \mathrm{d}x \\
&= \int_{\Gamma} \varphi \mathrm{d}f \\
&= -\int_{\Gamma} f \mathrm{d}\varphi = -\langle f, \varphi' \rangle
\end{aligned}
$$

这个定义和通常的导数定义是一致的，不难验证这个弱导数也满足通常导数的运算性质（线性性、乘法法则、链式法则等）。但按照S可积的条件，我们可以对任意有界变差函数定义分布意义上的**弱导数**。

于是形式上，任意的概率分布函数都可以定义一个广义密度函数$f(x)$了。

> 另一条路线是利用$\sigma$-有限测度和**Radon-Nikodym定理**对任意两个概率测度定义R-N导数，取其中一个为均匀分布则得到广义概率密度函数。但实际上和上面的过程是等价的。

## 大数定律

大数定律描述了随机变量序列的平均值收敛到其期望值的行为，弱大数定律描述了**依概率收敛**的情况，而强大数定律描述了**几乎必然收敛**的情况。

:::tip Khinchin弱大数定律
设$X_1, X_2, \cdots$是独立**同分布**的随机变量序列，且$\mathbb{E}(X_i) = \mu$，则对于任意$\varepsilon > 0$，有：

$$
\lim_{n \to \infty} \mathbb{P} \left( \left| \frac{1}{n} \sum_{i=1}^n X_i - \mu \right| \geq \varepsilon \right) = 0
$$

即

$$
\frac{1}{n} \sum_{i=1}^n X_i \overset{\mathbb{P}}{\to} \mu, \quad n \to \infty
$$

:::

:::tip Kolmogorov强大数定律
设$X_1, X_2, \cdots$是相互独立的随机变量序列，且$\mathbb{E}(X_i) = \mu_i$，$\displaystyle \sum_{i = 1}^{\infty} \dfrac{\mathbb{D}(X_i)}{i^2}<\infty$，则：

$$
 \mathbb{P}(\lim_{n \to \infty} \frac{1}{n} \sum_{i=1}^n (X_i - \mu_i) = 0) = 1
$$

即

$$
\frac{1}{n} \sum_{i=1}^n (X_i - \mu_i) \overset{a.s.}{\to} 0, \quad n \to \infty
$$

:::info 推论

若$X_1, X_2, \cdots$是独立随机变量序列，且具有相同的均值和方差，$\mathbb{E}(X) = \mu$，$\mathbb{D}(X)<\infty$，则：

$$
\frac{1}{n} \sum_{i=1}^n X_i \overset{a.s.}{\to} \mu, \quad n \to \infty
$$

> **证明**：注意著名的巴塞尔级数：$\displaystyle \sum_{i = 1}^{\infty} \dfrac{1}{i^2} = \dfrac{\pi^2}{6}$即可。

:::

注意辛钦弱大数定理并不要求方差存在，而Kolmogorov强大数定律则要求方差存在且有限。

:::info Further Reading

- 各种收敛间的关系：[Fiddie的概率论复习笔记(9)——几种收敛的关系](https://zhuanlan.zhihu.com/p/70034585)
- Kolmogorov强大数定律的证明：[Fiddie的概率论复习笔记(7)——Kolmogorov大数定律](https://zhuanlan.zhihu.com/p/69607174)

:::


